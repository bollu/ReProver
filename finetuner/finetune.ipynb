{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4606fcad-8d0d-48bb-af83-8e54ea45148a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: loguru in /anaconda/envs/py38_default/lib/python3.8/site-packages (0.7.0)\n",
      "Requirement already satisfied: transformers in /anaconda/envs/py38_default/lib/python3.8/site-packages (4.31.0)\n",
      "Requirement already satisfied: wandb in /anaconda/envs/py38_default/lib/python3.8/site-packages (0.15.8)\n",
      "Requirement already satisfied: accelerate in /anaconda/envs/py38_default/lib/python3.8/site-packages (0.21.0)\n",
      "Requirement already satisfied: datasets in /anaconda/envs/py38_default/lib/python3.8/site-packages (2.14.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from transformers) (1.23.0)\n",
      "Requirement already satisfied: requests in /anaconda/envs/py38_default/lib/python3.8/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: packaging>=20.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: filelock in /anaconda/envs/py38_default/lib/python3.8/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: setuptools in /anaconda/envs/py38_default/lib/python3.8/site-packages (from wandb) (65.5.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from wandb) (3.1.32)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: typing-extensions in /anaconda/envs/py38_default/lib/python3.8/site-packages (from wandb) (4.4.0)\n",
      "Requirement already satisfied: setproctitle in /anaconda/envs/py38_default/lib/python3.8/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from wandb) (1.29.2)\n",
      "Requirement already satisfied: pathtools in /anaconda/envs/py38_default/lib/python3.8/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from wandb) (3.19.6)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.9 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from transformers) (1.13.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /anaconda/envs/py38_default/lib/python3.8/site-packages (from datasets) (1.1.5)\n",
      "Requirement already satisfied: multiprocess in /anaconda/envs/py38_default/lib/python3.8/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: xxhash in /anaconda/envs/py38_default/lib/python3.8/site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: aiohttp in /anaconda/envs/py38_default/lib/python3.8/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: six>=1.4.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /anaconda/envs/py38_default/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install loguru transformers wandb transformers[torch] accelerate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "40ca3e26-17ac-4f84-997b-28ad5105cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Fine tune CodeT5 model on the FStar everest dataset.\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import datetime\n",
    "from typing import *\n",
    "from loguru import logger\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "import argparse\n",
    "from transformers.trainer_utils import EvalPrediction\n",
    "from transformers import (\n",
    "    AdamW, get_linear_schedule_with_warmup,\n",
    "    BertConfig, BertForMaskedLM, BertTokenizer,\n",
    "    GPT2Config, GPT2LMHeadModel, GPT2Tokenizer,\n",
    "    OpenAIGPTConfig, OpenAIGPTLMHeadModel, OpenAIGPTTokenizer,\n",
    "    RobertaConfig, RobertaModel, RobertaTokenizer,\n",
    "    DistilBertConfig, DistilBertForMaskedLM, DistilBertTokenizer,\n",
    ")\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import Seq2SeqTrainer,AutoTokenizer, T5ForConditionalGeneration,EarlyStoppingCallback, Seq2SeqTrainingArguments, AdamW, ProgressCallback\n",
    "\n",
    "# tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "# model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "\n",
    "# https://huggingface.co/transformers/v3.0.2/model_doc/t5.html#t5forconditionalgeneration\n",
    "# >>> from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "# \n",
    "# >>> tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "# >>> model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "# >>> input_ids = tokenizer.encode(\"Hello, my dog is cute\", return_tensors=\"pt\")  # Batch size 1\n",
    "# >>> outputs = model(input_ids=input_ids, decoder_input_ids=input_ids, labels=input_ids)\n",
    "# >>> loss, prediction_scores = outputs[:2]\n",
    "# \n",
    "# >>> tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "# >>> model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "# >>> input_ids = tokenizer.encode(\"summarize: Hello, my dog is cute\", return_tensors=\"pt\")  # Batch size 1\n",
    "# >>> outputs = model.generate(input_ids)\n",
    "#\n",
    "\n",
    "### Tutorial: https://huggingface.co/docs/transformers/main/tasks/masked_language_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "640da8a6-8bce-4e7b-ace9-762d9aacd31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='kaiyuy/leandojo-lean4-sst-byt5-small'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "max_model_length = tokenizer.model_max_length #for CodeT5 it is 512\n",
    "# print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c945a97b-81fe-47cf-b47e-7dbc7cfa5637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-11 01:30:49.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1m  0> out_str: have id (n : Nat) : Nat := fun _ ↦ id\u001b[0m\n",
      "\u001b[32m2023-08-11 01:30:49.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1m  1> out_str: exact id.def n ▸ go rfl\u001b[0m\n",
      "\u001b[32m2023-08-11 01:30:49.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1m  2> out_str: have id (n : Nat) : Nat := fun n h => h.symm ▸ Nat.le_refl..\u001b[0m\n",
      "\u001b[32m2023-08-11 01:30:49.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1m  3> out_str: have id (n : Nat) : Nat := fun _ h ↦ h\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "outs_ids = model.generate(tokenizer(\"def id (n : Nat) : Nat := \", return_tensors=\"pt\").input_ids,\n",
    "    max_length=1024,\n",
    "    num_beams=4,\n",
    "    length_penalty=0.0,\n",
    "    do_sample=False,\n",
    "    num_return_sequences=4,\n",
    "    early_stopping=False)\n",
    "for ix in range(len(outs_ids)):\n",
    "    out_str = tokenizer.decode(outs_ids[ix], skip_special_tokens=True)\n",
    "    logger.info(f\"{ix:3}> out_str: {out_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fb0e9134-c59b-48ee-92d9-bb3bde92d03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-11 01:30:49.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mmodel EOS token: </s>\u001b[0m\n",
      "\u001b[32m2023-08-11 01:30:49.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mspecial tokens: ['</s>', '<unk>', '<pad>', '<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', '<extra_id_100>', '<extra_id_101>', '<extra_id_102>', '<extra_id_103>', '<extra_id_104>', '<extra_id_105>', '<extra_id_106>', '<extra_id_107>', '<extra_id_108>', '<extra_id_109>', '<extra_id_110>', '<extra_id_111>', '<extra_id_112>', '<extra_id_113>', '<extra_id_114>', '<extra_id_115>', '<extra_id_116>', '<extra_id_117>', '<extra_id_118>', '<extra_id_119>', '<extra_id_120>', '<extra_id_121>', '<extra_id_122>', '<extra_id_123>', '<extra_id_124>']\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "eos_token = tokenizer.eos_token\n",
    "logger.info(f\"model EOS token: {eos_token}\")\n",
    "logger.info(f\"special tokens: {tokenizer.all_special_tokens}\")\n",
    "# #updating the tokenizer's vocalblary file with End of Statement <EOS> Special Token:\n",
    "# # print(\"Tokenizer's original size:  \",len(tokenizer))\n",
    "# special_tokens_dict = {'eos_token': '<EOS>'}\n",
    "# num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "# # print('\\n We have added', num_added_toks, 'token')\n",
    "# model.resize_token_embeddings(len(tokenizer))\n",
    "# # print(tokenizer.all_special_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "94bed5b8-06a4-4d19-aa93-d6ca3f5f84da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa5ce053-29b8-471c-814f-6f109ee0d4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/models/byt5/tokenization_byt5.py:149: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n",
      "\u001b[32m2023-08-11 01:30:50.072\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m33\u001b[0m - \u001b[34m\u001b[1meos token: </s> | encoded {'input_ids': [1], 'attention_mask': [1]}\u001b[0m\n",
      "\u001b[32m2023-08-11 01:30:50.072\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m34\u001b[0m - \u001b[34m\u001b[1mtokenizer tokenize: ['f', 'o', 'o', ' ', 'b', 'a', 'r', ' ', 'b', 'a', 'z', ' ', 'q', 'u', 'u', 'x', 'l', 'a', 'j', 'd', 'a', 's', 'd', 's', 'a', 'd', 'l', 'k', 'a']\u001b[0m\n",
      "\u001b[32m2023-08-11 01:30:50.073\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m35\u001b[0m - \u001b[34m\u001b[1mtokenizer funcall: {'input_ids': [105, 114, 114, 35, 101, 100, 117, 35, 101, 100, 125, 35, 116, 120, 120, 123, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\u001b[0m\n",
      "\u001b[32m2023-08-11 01:30:50.074\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1mconvert_tokens_to_ids: [105, 114, 114, 35, 101, 100, 117, 35, 101, 100, 125, 35, 116, 120, 120, 123, 35, 111, 100, 117, 115]\u001b[0m\n",
      "\u001b[32m2023-08-11 01:30:50.074\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m43\u001b[0m - \u001b[34m\u001b[1meos token: </s> | encoded {'input_ids': [1], 'attention_mask': [1]}\u001b[0m\n",
      "\u001b[32m2023-08-11 01:30:50.075\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mtokenizer tokenize: ['f', 'o', 'o', ' ', 'b', 'a', 'r', ' ', 'b', 'a', 'z', ' ', 'q', 'u', 'u', 'x', 'l', 'a', 'j', 'd', 'a', 's', 'd', 's', 'a', 'd', 'l', 'k', 'a']\u001b[0m\n",
      "\u001b[32m2023-08-11 01:30:50.075\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m45\u001b[0m - \u001b[34m\u001b[1mtokenizer funcall: {'input_ids': [105, 114, 114, 35, 101, 100, 117, 35, 101, 100, 125, 35, 116, 120, 120, 123, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\u001b[0m\n",
      "\u001b[32m2023-08-11 01:30:50.076\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m46\u001b[0m - \u001b[34m\u001b[1mconvert_tokens_to_ids: [105, 114, 114, 35, 101, 100, 117, 35, 101, 100, 125, 35, 116, 120, 120, 123, 35, 111, 100, 117, 115]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def get_label_ids_sakina(target):\n",
    "    \"\"\"\n",
    "    Why is it correct for the model to produce <EOS> at the end if we have too large a sentence?\n",
    "    Siddharth does not believe this implementation.\n",
    "    \"\"\"\n",
    "    max_length=tokenizer.model_max_length\n",
    "    # to train model on End of statement token. Even When model truncates longer code, EOS remain to show model the end of the statement\n",
    "    # Tokenize the target text without padding to get the tokens\n",
    "    encoded_tokens = tokenizer.tokenize(target)\n",
    "    # Check if the total number of tokens is greater than max_length\n",
    "    if len(encoded_tokens) > max_length:\n",
    "        # If yes, truncate the tokens while preserving the \"<EOS>\" at the end\n",
    "        truncated_tokens = encoded_tokens[:max_length - 1] + [encoded_tokens[-1]]\n",
    "        # Convert the truncated tokens back to input_ids\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(truncated_tokens)\n",
    "    else:\n",
    "        # If no truncation needed, keep the original tokens with padding\n",
    "        input_ids = tokenizer(target, max_length=max_length, padding=\"max_length\", truncation=True).input_ids\n",
    "    # print(input_ids)\n",
    "    return input_ids\n",
    "\n",
    "\n",
    "def get_label_ids(target):\n",
    "    \"\"\"\n",
    "    get  {'input_ids': [1, 11351, 4653, 29025, 719, 2616, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n",
    "    for input \"foo bar baz quux larp\"\n",
    "    \"\"\"\n",
    "    input_ids = tokenizer(target, max_length=max_length, padding=\"max_length\", truncation=True).input_ids\n",
    "    return input_ids\n",
    "\n",
    "if True: # testing\n",
    "    eos_encoded = tokenizer(tokenizer.eos_token)\n",
    "    logger.debug(f'eos token: {tokenizer.eos_token} | encoded {eos_encoded}')\n",
    "    logger.debug(f'tokenizer tokenize: {tokenizer.tokenize(\"foo bar baz quuxlajdasdsadlka\")}')\n",
    "    logger.debug(f'tokenizer funcall: {tokenizer(\"foo bar baz quux\")}')\n",
    "    logger.debug(f'convert_tokens_to_ids: {tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"foo bar baz quux larp\"))}')\n",
    "# tokenize: string -> List[token=str]\n",
    "# convert_tokens_to_ids: List[token=str] -> List[int]\n",
    "# tokenizer(...) = convert_tokns_to_ids . tokenize + attention mask.\n",
    "# \n",
    "if True: # testing\n",
    "    eos_encoded = tokenizer(tokenizer.eos_token)\n",
    "    logger.debug(f'eos token: {tokenizer.eos_token} | encoded {eos_encoded}')\n",
    "    logger.debug(f'tokenizer tokenize: {tokenizer.tokenize(\"foo bar baz quuxlajdasdsadlka\")}')\n",
    "    logger.debug(f'tokenizer funcall: {tokenizer(\"foo bar baz quux\")}')\n",
    "    logger.debug(f'convert_tokens_to_ids: {tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"foo bar baz quux larp\"))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b5de7be8-ccfb-4b18-8a73-9e9dd902a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maping the dataset into batches\n",
    "Experiment = True # for the first experimental run to get the pipeline going\n",
    "if Experiment and not os.path.exists(\"input.txt\"):\n",
    "    # Download Shakespeare\n",
    "    %time\n",
    "    !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "66626f42-d850-4996-b782-8c21a0785ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 2699/2699 [00:32<00:00, 84.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input': 'val finv: res:felem -> a:felem -> Stack unit\\n\\n  (requires fun h ->\\n\\n    live h a /\\\\ live h res /\\\\ eq_or_disjoint a res /\\\\\\n\\n    as_nat h a < S.prime)\\n\\n  (ensures fun h0 _ h1 -> modifies (loc res) h0 h1 /\\\\\\n\\n    as_nat h1 res < S.prime /\\\\\\n</s>'}, {'input': 'val fsqrt: res:felem -> a:felem -> Stack unit\\n\\n  (requires fun h ->\\n\\n    live h a /\\\\ live h res /\\\\ eq_or_disjoint a res /\\\\\\n\\n    as_nat h a < S.prime)\\n\\n  (ensures fun h0 _ h1 -> modifies (loc res) h0 h1 /\\\\\\n\\n    as_nat h1 res < S.prime /\\\\\\n</s>'}, {'input': \"type t19' =\\n\\n  | X_a of (squash False)\\n</s>\"}]\n",
      "#defs: 49728\n",
      "grabbed output from #files: 2647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import tqdm\n",
    "import json\n",
    "import pathlib\n",
    "import glob\n",
    "\n",
    "defs = []\n",
    "\n",
    "files = set()\n",
    "for jpath in tqdm.tqdm(glob.glob(\"dataset/*.json\")):\n",
    "    j = json.loads(open(jpath, \"r\").read())\n",
    "    for jdefn in j[\"defs\"]:\n",
    "        filepath = pathlib.Path(jdefn[\"file_name\"]).name \n",
    "        files.add(filepath)\n",
    "        data = open(f\"./raw_dataset/{filepath}\").readlines()\n",
    "        start_line = int(jdefn[\"start_line\"])\n",
    "        end_line = int(jdefn[\"end_line\"])\n",
    "        if start_line == 0: continue # start line is zero.\n",
    "        data = \"\\n\".join(data[start_line-1:end_line-1])\n",
    "        if data:\n",
    "            defs.append({\"input\": data + tokenizer.eos_token})\n",
    "        \n",
    "print(defs[:3])\n",
    "print(f\"#defs: {len(defs)}\")\n",
    "files = sorted(list(files))\n",
    "print(f\"grabbed output from #files: {len(files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "373f260a-51d5-484b-ae65-559adaf00857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815d6ab3583d4c23b358820a7c247aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/39782 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/models/byt5/tokenization_byt5.py:149: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n",
      "/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/models/byt5/tokenization_byt5.py:149: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n",
      "/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/models/byt5/tokenization_byt5.py:149: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n",
      "/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/models/byt5/tokenization_byt5.py:149: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c900306a64564856ab0090e36ab369f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/39782 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b73587c02d64026afc71c7dbd695a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4973 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/models/byt5/tokenization_byt5.py:149: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n",
      "/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/models/byt5/tokenization_byt5.py:149: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n",
      "/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/models/byt5/tokenization_byt5.py:149: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n",
      "/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/models/byt5/tokenization_byt5.py:149: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3c2efdcbf94c7f997891a3480d2dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4973 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321caa60fc2745fc8ce08eced8b16c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4973 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/models/byt5/tokenization_byt5.py:149: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n",
      "/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/models/byt5/tokenization_byt5.py:149: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n",
      "/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/models/byt5/tokenization_byt5.py:149: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n",
      "/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/models/byt5/tokenization_byt5.py:149: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816c00a3cb794a5d9f561d6ab6443d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4973 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-11 01:59:07.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mlen train: 39782 | test: 4973 | valid: 4973\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb\n",
    "### Tutorial: https://huggingface.co/docs/transformers/main/tasks/masked_language_modeling\n",
    "def build_huggingface_dataset_from_list_of_defs(defs: List[Dict[str, Any]]) -> datasets.Dataset:\n",
    "    dataset = datasets.Dataset.from_list(defs)\n",
    "    dataset = dataset.map(lambda egs : tokenizer(egs[\"input\"]), batched=True, num_proc=4)\n",
    "    dataset = dataset.remove_columns([\"input\"]) # delete the key that is not a list of ints.\n",
    "    block_size = 128\n",
    "    def group_texts(examples):\n",
    "        # Concatenate all texts.\n",
    "        concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()} # collapse everything into a single [int]\n",
    "        # concatenated_examples = examples\n",
    "        total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "        # We drop the small remainder, though you could add padding instead if the model supports it\n",
    "        # In this, as in all things, we advise you to follow your heart\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "        # Split by chunks of max_len.\n",
    "        result = {\n",
    "            k: [v[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "            for k, v in concatenated_examples.items()\n",
    "        } # split stuff into new [int]\n",
    "        result[\"labels\"] = result[\"input_ids\"].copy() # not sure why this is correct -_^, ah yes it's correct because we are trying to do next token prediction.\n",
    "        return result\n",
    "    dataset = dataset.map(group_texts, batched=True, batch_size=1000, num_proc=4)\n",
    "    return dataset \n",
    "\n",
    "TOTAL_LEN = len(defs)\n",
    "TRAIN_SPLIT_IX = int(TOTAL_LEN*0.8)\n",
    "VALID_SPLIT_IX = int(TOTAL_LEN*0.9)\n",
    "train_dataset = build_huggingface_dataset_from_list_of_defs(defs[:TRAIN_SPLIT_IX])\n",
    "valid_dataset = build_huggingface_dataset_from_list_of_defs(defs[TRAIN_SPLIT_IX:VALID_SPLIT_IX])\n",
    "test_dataset = build_huggingface_dataset_from_list_of_defs(defs[VALID_SPLIT_IX:])\n",
    "logger.info(f\"len train: {TRAIN_SPLIT_IX} | test: {VALID_SPLIT_IX - TRAIN_SPLIT_IX} | valid: {TOTAL_LEN-VALID_SPLIT_IX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fa5117b9-d5a5-4fa0-852e-99469c7133b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_eg keys: dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
      "train_eg len: [128, 128, 128]\n",
      "train_eg vals: [('input_ids', [121]), ('attention_mask', [1]), ('labels', [121])]\n"
     ]
    }
   ],
   "source": [
    "def debug():\n",
    "    train_eg = next(iter(train_dataset))\n",
    "    print(f\"train_eg keys: {train_eg.keys()}\")\n",
    "    print(f\"train_eg len: {[len(train_eg[k]) for k in train_eg.keys()]}\")\n",
    "    print(f\"train_eg vals: {[(k, train_eg[k][:1]) for k in train_eg.keys()]}\")\n",
    "    \n",
    "    # train_eg_input = train_eg['input']\n",
    "    # print(f\"train_eg input: {type(train_eg_input)} | len : {len(train_eg_input)}\")\n",
    "    # print(f\"input[0]: {train_eg_input[0][:90]}\")\n",
    "debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0e8795d3-d605-451a-804f-a5b204761b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output_dir\",\n",
    "    learning_rate=1e-3, # should I use a much smaller learning rate?\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=1e-2,\n",
    "    logging_steps=1,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=10\n",
    ")\n",
    "training_args = training_args.set_dataloader(train_batch_size=512, eval_batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9e3c5bc9-383c-4706-9b83-9bb613bc10a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:hnk9qmq1) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">efficient-breeze-10</strong> at: <a href='https://wandb.ai/microsoft-research-incubation/lean3-codet5-finetune-fstar/runs/hnk9qmq1' target=\"_blank\">https://wandb.ai/microsoft-research-incubation/lean3-codet5-finetune-fstar/runs/hnk9qmq1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230811_015231-hnk9qmq1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:hnk9qmq1). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/t-sibhat/neural-premise-selection/src/Projects/premise-selection/ReProver/finetuner/wandb/run-20230811_015928-9ppzrr2u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/microsoft-research-incubation/lean3-codet5-finetune-fstar/runs/9ppzrr2u' target=\"_blank\">fallen-pine-11</a></strong> to <a href='https://wandb.ai/microsoft-research-incubation/lean3-codet5-finetune-fstar' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/microsoft-research-incubation/lean3-codet5-finetune-fstar' target=\"_blank\">https://wandb.ai/microsoft-research-incubation/lean3-codet5-finetune-fstar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/microsoft-research-incubation/lean3-codet5-finetune-fstar/runs/9ppzrr2u' target=\"_blank\">https://wandb.ai/microsoft-research-incubation/lean3-codet5-finetune-fstar/runs/9ppzrr2u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Changing param values is not allowed. Param with key='logging_dir' was already logged with value='output_dir/runs/Aug11_01-52-30_GCRAZGDL2210' for run ID='028e744ce2ad46c381c6d198aad0f82d'. Attempted logging new value 'output_dir/runs/Aug11_01-59-21_GCRAZGDL2210'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py:1021\u001b[0m, in \u001b[0;36mFileStore.log_batch\u001b[0;34m(self, run_id, metrics, params, tags)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_run_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics:\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py:926\u001b[0m, in \u001b[0;36mFileStore._log_run_param\u001b[0;34m(self, run_info, param)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(param_path):\n\u001b[0;32m--> 926\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_new_param_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparam_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparam_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriteable_param_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m make_containing_dirs(param_path)\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py:946\u001b[0m, in \u001b[0;36mFileStore._validate_new_param_value\u001b[0;34m(self, param_path, param_key, run_id, new_value)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_value \u001b[38;5;241m!=\u001b[39m new_value:\n\u001b[0;32m--> 946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChanging param values is not allowed. Param with key=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m was already\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m logged with value=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for run ID=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Attempted logging\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m new value \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    950\u001b[0m         databricks_pb2\u001b[38;5;241m.\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[1;32m    951\u001b[0m     )\n",
      "\u001b[0;31mMlflowException\u001b[0m: Changing param values is not allowed. Param with key='logging_dir' was already logged with value='output_dir/runs/Aug11_01-52-30_GCRAZGDL2210' for run ID='028e744ce2ad46c381c6d198aad0f82d'. Attempted logging new value 'output_dir/runs/Aug11_01-59-21_GCRAZGDL2210'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 20\u001b[0m\n\u001b[1;32m     12\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     13\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     14\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m elapsed_time_secs \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1536\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1538\u001b[0m )\n\u001b[0;32m-> 1539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/trainer.py:1752\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step\n\u001b[1;32m   1750\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m-> 1752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;66;03m# Skip the first epochs_trained epochs to get the random state of the dataloader at the right point.\u001b[39;00m\n\u001b[1;32m   1755\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mignore_data_skip:\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/trainer_callback.py:353\u001b[0m, in \u001b[0;36mCallbackHandler.on_train_begin\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_begin\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[1;32m    352\u001b[0m     control\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_event\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_train_begin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/trainer_callback.py:397\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_event\u001b[39m(\u001b[38;5;28mself\u001b[39m, event, args, state, control, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 397\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;66;03m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/integrations.py:1017\u001b[0m, in \u001b[0;36mMLflowCallback.on_train_begin\u001b[0;34m(self, args, state, control, model, **kwargs)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_begin\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, state, control, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialized:\n\u001b[0;32m-> 1017\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/integrations.py:1008\u001b[0m, in \u001b[0;36mMLflowCallback.setup\u001b[0;34m(self, args, state, model)\u001b[0m\n\u001b[1;32m   1006\u001b[0m combined_dict_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(combined_dict\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(combined_dict_items), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_MAX_PARAMS_TAGS_PER_BATCH):\n\u001b[0;32m-> 1008\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ml_flow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_params\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcombined_dict_items\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_MAX_PARAMS_TAGS_PER_BATCH\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m mlflow_tags \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLFLOW_TAGS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mlflow_tags:\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/mlflow/tracking/fluent.py:699\u001b[0m, in \u001b[0;36mlog_params\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    697\u001b[0m run_id \u001b[38;5;241m=\u001b[39m _get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[1;32m    698\u001b[0m params_arr \u001b[38;5;241m=\u001b[39m [Param(key, \u001b[38;5;28mstr\u001b[39m(value)) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[0;32m--> 699\u001b[0m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/mlflow/tracking/client.py:965\u001b[0m, in \u001b[0;36mMlflowClient.log_batch\u001b[0;34m(self, run_id, metrics, params, tags)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_batch\u001b[39m(\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    910\u001b[0m     run_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m     tags: Sequence[RunTag] \u001b[38;5;241m=\u001b[39m (),\n\u001b[1;32m    914\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    915\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;124;03m    Log multiple metrics, params, and/or tags.\u001b[39;00m\n\u001b[1;32m    917\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;124;03m        status: FINISHED\u001b[39;00m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 965\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/mlflow/tracking/_tracking_service/client.py:389\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_batch\u001b[0;34m(self, run_id, metrics, params, tags)\u001b[0m\n\u001b[1;32m    386\u001b[0m     metrics_batch \u001b[38;5;241m=\u001b[39m metrics[:metrics_batch_size]\n\u001b[1;32m    387\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m metrics[metrics_batch_size:]\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags_batch\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metrics_batch \u001b[38;5;129;01min\u001b[39;00m chunk_list(metrics, chunk_size\u001b[38;5;241m=\u001b[39mMAX_METRICS_PER_BATCH):\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mlog_batch(run_id\u001b[38;5;241m=\u001b[39mrun_id, metrics\u001b[38;5;241m=\u001b[39mmetrics_batch, params\u001b[38;5;241m=\u001b[39m[], tags\u001b[38;5;241m=\u001b[39m[])\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py:1032\u001b[0m, in \u001b[0;36mFileStore.log_batch\u001b[0;34m(self, run_id, metrics, params, tags)\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_run_tag(run_info, tag)\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1032\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(e, INTERNAL_ERROR)\n",
      "\u001b[0;31mMlflowException\u001b[0m: Changing param values is not allowed. Param with key='logging_dir' was already logged with value='output_dir/runs/Aug11_01-52-30_GCRAZGDL2210' for run ID='028e744ce2ad46c381c6d198aad0f82d'. Attempted logging new value 'output_dir/runs/Aug11_01-59-21_GCRAZGDL2210'."
     ]
    }
   ],
   "source": [
    "import time\n",
    "from transformers import Trainer\n",
    "run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"lean3-codet5-finetune-fstar\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={})\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,\n",
    "                                                mlm=False) # no masked language modelling\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "\n",
    "elapsed_time_secs = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a84730-9540-4b04-a86d-0559587a284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./output_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a40abd-8f79-4b97-bb6a-b0b4531b9ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "model_gen = T5ForConditionalGeneration.from_pretrained(\"./output_dir\")\n",
    "# model_gen = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-small\")\n",
    "outs_ids = model_gen.generate(tokenizer(\"live h a /\\ \", return_tensors=\"pt\").input_ids,\n",
    "    max_length=1024,\n",
    "    num_beams=4,\n",
    "    length_penalty=0.0,\n",
    "    do_sample=False,\n",
    "    num_return_sequences=4,\n",
    "    early_stopping=False)\n",
    "out_str = tokenizer.decode(outs_ids[0], skip_special_tokens=True)\n",
    "print(out_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cbcd97-cb11-443e-b599-57e123e5c439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
